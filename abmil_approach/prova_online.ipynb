{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32121dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_feat import ImageBagDataset, transform, End2EndABMIL\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchmil.data import collate_fn\n",
    "from train_val import train, val\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f033e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = \"C:\\\\Users\\\\utente\\\\Documents\\\\UNI\\\\MAGISTRALE\\\\tesi\\\\raw_dataset\\\\artifacts\\\\embeddings\\\\features\"\n",
    "labels_path = \"C:\\\\Users\\\\utente\\\\Documents\\\\UNI\\\\MAGISTRALE\\\\tesi\\\\raw_dataset\\\\artifacts\\\\embeddings\\\\labels\"\n",
    "root_dir = \"C:\\\\Users\\\\utente\\\\Documents\\\\UNI\\\\MAGISTRALE\\\\tesi\\\\raw_dataset\\\\artifacts\\\\Dataset\"\n",
    "annotations_file = \"C:\\\\Users\\\\utente\\\\Documents\\\\UNI\\\\MAGISTRALE\\\\tesi\\\\raw_dataset\\\\artifacts\\\\clinical_case_metadata.parquet\"\n",
    "k_folds=5\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b44d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = ImageBagDataset(root_dir, annotations_file, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9a4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = End2EndABMIL(False).to(device)\n",
    "#emb = model(dataset[0]['X'])\n",
    "#dataset[0]['X'].unsqueeze(0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48ae782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb2 = np.load(\"C:\\\\Users\\\\utente\\\\Documents\\\\UNI\\\\MAGISTRALE\\\\tesi\\\\raw_dataset\\\\artifacts\\\\embeddings\\\\features16\\\\5H6mQZJMmqo9LPcFd1QOW.npy\")\n",
    "#emb2 = torch.tensor(emb2)\n",
    "#emb2 = emb2.unsqueeze(0)\n",
    "#print(emb[0][0], emb2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "596b1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed=0\n",
    "#torch.manual_seed(seed)\n",
    "#random.seed(seed)\n",
    "#np.random.seed(seed)\n",
    "#mil = ABMIL((1024,), 256, \"relu\")\n",
    "#print(mil(emb), mil(emb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1617d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(k_folds, shuffle=True)\n",
    "dataset = ImageBagDataset(root_dir, annotations_file, transform)\n",
    "bag_labels = [dataset[i][\"Y\"].item() for i in range(len(dataset))]\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "for _, (train_idx, val_idx) in enumerate(cv.split(np.zeros(len(bag_labels)), bag_labels)):\n",
    "    train_data.append(Subset(dataset, train_idx))\n",
    "    val_data.append(Subset(dataset, val_idx))\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data[0], batch_size=2, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_data[0], batch_size=2, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1b32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_train = End2EndABMIL(train_last_block=True)\n",
    "model_freeze = End2EndABMIL(train_last_block=False)\n",
    "model_train.to(device)\n",
    "model_freeze.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_train = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_train.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "optimizer_freeze = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_freeze.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "#data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def set_frozen_modules_to_eval(model: nn.Module):\n",
    "    for name, module in model.named_modules():\n",
    "        # Skip the top-level module itself\n",
    "        if module is model:\n",
    "            continue\n",
    "\n",
    "        params = list(module.parameters(recurse=False))\n",
    "        if not params:\n",
    "            continue\n",
    "\n",
    "        # Check if all parameters in this module are frozen\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.eval()\n",
    "        if all(not p.requires_grad for p in params):\n",
    "            module.eval()\n",
    "\n",
    "set_frozen_modules_to_eval(model_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "069e6699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss:  0.7282 | Val Loss:  0.7320\n",
      "Epoch 2 | Train Loss:  0.7337 | Val Loss:  0.7050\n",
      "Epoch 3 | Train Loss:  0.7091 | Val Loss:  0.6726\n",
      "Epoch 4 | Train Loss:  0.6761 | Val Loss:  0.6455\n",
      "Epoch 5 | Train Loss:  0.6628 | Val Loss:  0.6268\n",
      "Epoch 6 | Train Loss:  0.6552 | Val Loss:  0.6133\n",
      "Epoch 7 | Train Loss:  0.6295 | Val Loss:  0.6101\n",
      "Epoch 8 | Train Loss:  0.6225 | Val Loss:  0.6046\n",
      "Epoch 9 | Train Loss:  0.6250 | Val Loss:  0.6015\n",
      "Epoch 10 | Train Loss:  0.5931 | Val Loss:  0.6015\n"
     ]
    }
   ],
   "source": [
    "#print(\"\\tTRAINING\\t\\t\\t\\t\\t\\t\\tVALIDATION\")\n",
    "for epoch in range(10):     \n",
    "    #train_losst, train_acct = train(model_train, device, criterion, optimizer_train, train_dataloader)\n",
    "    train_lossf, train_accf = train(model_freeze, device, criterion, optimizer_freeze, train_dataloader)\n",
    "\n",
    "    #val_losst, val_acct, stop = val(model_train, device, criterion, val_dataloader, epoch, additional_metrics=False)\n",
    "    val_lossf, val_accf, stop = val(model_freeze, device, criterion, val_dataloader, epoch, additional_metrics=False)\n",
    "\n",
    "    #print(f\"lt: {train_losst: .4f}\\t lf: {train_lossf: .4f}\\t at: {train_acct: .4f}\\t af {train_accf: .4f}\\t||\\tlt: {val_losst: .4f}\\t lf: {val_lossf: .4f}\\t at: {val_acct: .4f}\\t af {val_accf: .4f}\")\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_lossf: .4f} | Val Loss: {val_lossf: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d71f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss:  0.7355 | Val Loss:  0.5645\n",
      "Epoch 2 | Train Loss:  0.5971 | Val Loss:  0.5471\n",
      "Epoch 3 | Train Loss:  0.5014 | Val Loss:  0.5474\n",
      "Epoch 4 | Train Loss:  0.4201 | Val Loss:  0.5423\n",
      "Epoch 5 | Train Loss:  0.4020 | Val Loss:  0.5577\n",
      "Epoch 6 | Train Loss:  0.3492 | Val Loss:  0.5572\n",
      "Epoch 7 | Train Loss:  0.2389 | Val Loss:  0.5682\n",
      "Epoch 8 | Train Loss:  0.1754 | Val Loss:  0.6433\n",
      "Epoch 9 | Train Loss:  0.4226 | Val Loss:  0.5891\n",
      "Epoch 10 | Train Loss:  0.2614 | Val Loss:  0.6341\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):     \n",
    "    #train_losst, train_acct = train(model_train, device, criterion, optimizer_train, train_dataloader)\n",
    "    train_lossf, train_accf = train(model_train, device, criterion, optimizer_train, train_dataloader)\n",
    "\n",
    "    #val_losst, val_acct, stop = val(model_train, device, criterion, val_dataloader, epoch, additional_metrics=False)\n",
    "    val_lossf, val_accf, stop = val(model_train, device, criterion, val_dataloader, epoch, additional_metrics=False)\n",
    "\n",
    "    #print(f\"lt: {train_losst: .4f}\\t lf: {train_lossf: .4f}\\t at: {train_acct: .4f}\\t af {train_accf: .4f}\\t||\\tlt: {val_losst: .4f}\\t lf: {val_lossf: .4f}\\t at: {val_acct: .4f}\\t af {val_accf: .4f}\")\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_lossf: .4f} | Val Loss: {val_lossf: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953acf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
