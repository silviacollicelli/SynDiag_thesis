{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6de8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa0c9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# serous_cystadenoma items: 103\n",
      "# high_grade_serous_adenocarcinoma items: 101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tab=pd.read_parquet(\"/home/silvia.collicelli/data/controlled_dataset_metadata.parquet\")\n",
    "#tab=tab[[\"histological\"]]\n",
    "ser_cyst_items=0\n",
    "ser_adeno_items=0\n",
    "for i in range(len(tab)):\n",
    "    if tab[\"histological\"][i]==\"serous_cystadenoma\":\n",
    "        ser_cyst_items+=1\n",
    "    elif tab[\"histological\"][i]==\"high_grade_serous_adenocarcinoma\":\n",
    "        ser_adeno_items+=1\n",
    "\n",
    "print(f\"# serous_cystadenoma items: {ser_cyst_items}\\n# high_grade_serous_adenocarcinoma items: {ser_adeno_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42eecb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clinical_case</th>\n",
       "      <th>item</th>\n",
       "      <th>project</th>\n",
       "      <th>histological</th>\n",
       "      <th>holsbeke_histological</th>\n",
       "      <th>risk_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shkRZET6mmL4-FiMzwAMu</td>\n",
       "      <td>lu6unBTi4Su1oU5nTJwng</td>\n",
       "      <td>sant_anna_retrospective</td>\n",
       "      <td>borderline_serous</td>\n",
       "      <td>serous_borderline</td>\n",
       "      <td>borderline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fUoEo2pkdf3ktT1W1Ao5T</td>\n",
       "      <td>_j7-y9fZ1Ezk08JU3nXIR</td>\n",
       "      <td>sant_anna_retrospective</td>\n",
       "      <td>clear_cell_carcinoma</td>\n",
       "      <td>epithelial_invasive</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fUoEo2pkdf3ktT1W1Ao5T</td>\n",
       "      <td>5EXdi4wJzDwaHuFlke6aP</td>\n",
       "      <td>sant_anna_retrospective</td>\n",
       "      <td>clear_cell_carcinoma</td>\n",
       "      <td>epithelial_invasive</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mwDM_iVesgkalPOuDycKR</td>\n",
       "      <td>q-WtFeF8r5PHOroTmL1QP</td>\n",
       "      <td>sant_anna_retrospective</td>\n",
       "      <td>endometrioid_adenocarcinoma</td>\n",
       "      <td>epithelial_invasive</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mwDM_iVesgkalPOuDycKR</td>\n",
       "      <td>Vr-fFU3yNFhJomRISALHr</td>\n",
       "      <td>sant_anna_retrospective</td>\n",
       "      <td>endometrioid_adenocarcinoma</td>\n",
       "      <td>epithelial_invasive</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>6P7oqKgYkb6dLm8IfyStw</td>\n",
       "      <td>MbLuXWyPT7gkHCxqRvmvE</td>\n",
       "      <td>sant_anna_retrospective</td>\n",
       "      <td>metastasis_group_1</td>\n",
       "      <td>metastasis</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>6P7oqKgYkb6dLm8IfyStw</td>\n",
       "      <td>_KYUppkTQgofR6q5P5sOW</td>\n",
       "      <td>sant_anna_retrospective</td>\n",
       "      <td>metastasis_group_1</td>\n",
       "      <td>metastasis</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>SSAYCSmb7dPXwF417EPAt</td>\n",
       "      <td>ntufz658SOutSunGZulax</td>\n",
       "      <td>ichilov</td>\n",
       "      <td>borderline_serous</td>\n",
       "      <td>serous_borderline</td>\n",
       "      <td>borderline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>SSAYCSmb7dPXwF417EPAt</td>\n",
       "      <td>Ls2lGITO5Pm9eDH1n_i5t</td>\n",
       "      <td>ichilov</td>\n",
       "      <td>borderline_serous</td>\n",
       "      <td>serous_borderline</td>\n",
       "      <td>borderline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>SSAYCSmb7dPXwF417EPAt</td>\n",
       "      <td>kpUV7b3iJ2AdAfLngPgW9</td>\n",
       "      <td>ichilov</td>\n",
       "      <td>borderline_serous</td>\n",
       "      <td>serous_borderline</td>\n",
       "      <td>borderline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>828 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             clinical_case                   item                  project  \\\n",
       "0    shkRZET6mmL4-FiMzwAMu  lu6unBTi4Su1oU5nTJwng  sant_anna_retrospective   \n",
       "1    fUoEo2pkdf3ktT1W1Ao5T  _j7-y9fZ1Ezk08JU3nXIR  sant_anna_retrospective   \n",
       "2    fUoEo2pkdf3ktT1W1Ao5T  5EXdi4wJzDwaHuFlke6aP  sant_anna_retrospective   \n",
       "3    mwDM_iVesgkalPOuDycKR  q-WtFeF8r5PHOroTmL1QP  sant_anna_retrospective   \n",
       "4    mwDM_iVesgkalPOuDycKR  Vr-fFU3yNFhJomRISALHr  sant_anna_retrospective   \n",
       "..                     ...                    ...                      ...   \n",
       "823  6P7oqKgYkb6dLm8IfyStw  MbLuXWyPT7gkHCxqRvmvE  sant_anna_retrospective   \n",
       "824  6P7oqKgYkb6dLm8IfyStw  _KYUppkTQgofR6q5P5sOW  sant_anna_retrospective   \n",
       "825  SSAYCSmb7dPXwF417EPAt  ntufz658SOutSunGZulax                  ichilov   \n",
       "826  SSAYCSmb7dPXwF417EPAt  Ls2lGITO5Pm9eDH1n_i5t                  ichilov   \n",
       "827  SSAYCSmb7dPXwF417EPAt  kpUV7b3iJ2AdAfLngPgW9                  ichilov   \n",
       "\n",
       "                    histological holsbeke_histological  risk_class  \n",
       "0              borderline_serous     serous_borderline  borderline  \n",
       "1           clear_cell_carcinoma   epithelial_invasive   malignant  \n",
       "2           clear_cell_carcinoma   epithelial_invasive   malignant  \n",
       "3    endometrioid_adenocarcinoma   epithelial_invasive   malignant  \n",
       "4    endometrioid_adenocarcinoma   epithelial_invasive   malignant  \n",
       "..                           ...                   ...         ...  \n",
       "823           metastasis_group_1            metastasis   malignant  \n",
       "824           metastasis_group_1            metastasis   malignant  \n",
       "825            borderline_serous     serous_borderline  borderline  \n",
       "826            borderline_serous     serous_borderline  borderline  \n",
       "827            borderline_serous     serous_borderline  borderline  \n",
       "\n",
       "[828 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c2261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serous_borderline': 'borderline',\n",
       " 'epithelial_invasive': 'malignant',\n",
       " 'cystadenoma-fibroma': 'benign',\n",
       " 'fibroma': 'benign',\n",
       " 'endometrioma': 'benign',\n",
       " 'metastasis': 'malignant',\n",
       " 'dermoid': 'benign',\n",
       " 'other_borderline': 'borderline',\n",
       " 'mucinous_borderline': 'borderline',\n",
       " 'simple_cyst-functional_cyst': 'benign',\n",
       " 'rare_benign_tumor': 'benign',\n",
       " 'abscess': 'benign',\n",
       " 'non_epithelial_invasive': 'malignant',\n",
       " 'hydrosalpinx': 'benign'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risks = dict(zip(tab['holsbeke_histological'], tab['risk_class']))\n",
    "risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02fe942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epithelial_invasive cases: 148\n",
      "# cystadenoma-fibroma cases: 135\n",
      "# fibroma cases: 45\n",
      "# endometrioma cases: 24\n",
      "#benign cases: 204\n",
      "tot cases 352\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "data_folder = \"/home/silvia.collicelli/data/Dataset\"\n",
    "epit_inv_cases=0\n",
    "fibroma_cases=0\n",
    "endometrioma_cases = 0\n",
    "cyst_fibr_cases=0\n",
    "img_labels = dict(zip(tab['clinical_case'], tab['holsbeke_histological']))\n",
    "for entry in os.scandir(data_folder):\n",
    "    if img_labels[entry.name]=='epithelial_invasive':\n",
    "        epit_inv_cases+=1\n",
    "    if img_labels[entry.name]=='cystadenoma-fibroma':\n",
    "        cyst_fibr_cases+=1\n",
    "    if img_labels[entry.name]=='fibroma':\n",
    "        fibroma_cases+=1\n",
    "    if img_labels[entry.name]=='endometrioma':\n",
    "        endometrioma_cases+=1\n",
    "\n",
    "        \n",
    "print(f\"# epithelial_invasive cases: {epit_inv_cases}\\n# cystadenoma-fibroma cases: {cyst_fibr_cases}\\n# fibroma cases: {fibroma_cases}\\n# endometrioma cases: {endometrioma_cases}\\n#benign cases: {fibroma_cases+endometrioma_cases+cyst_fibr_cases}\\ntot cases {fibroma_cases+endometrioma_cases+cyst_fibr_cases+epit_inv_cases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb2dfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(os.listdir(data_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e7734a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set determinism\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b17cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#is this transform  okay?\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e59264e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the frames from a video and save them in a folder called frames\n",
    "def extract_save_frames(video_path, output_dir, idx_des_frames=[], not_all_frames=False):    \n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)       #elimina la cartella già presente se c'è\n",
    "    os.makedirs(output_dir, exist_ok=True) \n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    i, id, s = 0, 0 ,0\n",
    "\n",
    "    while True:\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        if not_all_frames:\n",
    "            if id < len(idx_des_frames) and i == idx_des_frames[id]:\n",
    "                frame_path = os.path.join(output_dir, f\"frame_{i:04d}.jpeg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                s += 1\n",
    "                id += 1\n",
    "        else:\n",
    "            frame_path = os.path.join(output_dir, f\"frame_{i:04d}.jpeg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            s += 1\n",
    "\n",
    "        i+=1  \n",
    "    return s\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=img_tensor.device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=img_tensor.device)\n",
    "    img_tensor = img_tensor * std[:, None, None] + mean[:, None, None]\n",
    "    return img_tensor.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09c3ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_image_table(images, predicted, labels, probs):\n",
    "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
    "    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(2)])\n",
    "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
    "        img = denormalize(img)\n",
    "        table.add_data(wandb.Image((img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)), pred, targ, *prob.numpy())\n",
    "    wandb.log({\"predictions_table\":table}, commit=False)\n",
    "\n",
    "#specificity = true negative rate\n",
    "#sensitivity = true positive rate\n",
    "#malignant 1 -> positive\n",
    "#benign 0 -> negative\n",
    "\n",
    "def validate_model(model, valid_dl, loss_func, device, log_images=False, batch_idx=0, class_names=None):\n",
    "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    model.eval()\n",
    "    correct, val_loss = 0, 0.0\n",
    "    all_preds, all_labels, all_prob, all_pos_prob = [], [], [], []\n",
    "    sensitivity, specificity, all_pos, all_neg = 0.0, 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            pos_prob = outputs.softmax(dim=1)[:,1]\n",
    "            val_loss += loss_func(outputs, labels)*labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_pos_prob.extend(pos_prob.cpu().numpy())\n",
    "            all_prob.extend(outputs.softmax(dim=1).cpu().numpy())\n",
    "\n",
    "            # Log one batch of images to the dashboard, always same batch_idx.\n",
    "            if i==batch_idx and log_images:\n",
    "                log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
    "        \n",
    "        all_labels = np.array(all_labels, dtype=int)\n",
    "        all_pos_prob = np.array(all_pos_prob, dtype=float)\n",
    "        all_prob = np.array(all_prob, dtype=float)\n",
    "\n",
    "        for i in range(len(all_labels)):\n",
    "            if all_labels[i] == 1: \n",
    "                all_pos += 1\n",
    "                if all_labels[i] == all_preds[i]:\n",
    "                    sensitivity += 1\n",
    "            elif all_labels[i] == 0:\n",
    "                all_neg += 1\n",
    "                if all_labels[i] == all_preds[i]:\n",
    "                    specificity += 1\n",
    "        \n",
    "        # Compute global metrics\n",
    "        sensitivity /= all_pos\n",
    "        specificity /= all_neg\n",
    "        val_loss /= len(valid_dl.dataset)\n",
    "        acc = correct / len(valid_dl.dataset)\n",
    "        auc = roc_auc_score(all_labels, all_pos_prob)\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "        #wandb.log({\n",
    "        #    \"conf_mat\": wandb.plot.confusion_matrix(\n",
    "        #        preds=all_preds,\n",
    "        #        y_true=all_labels,\n",
    "        #        class_names=class_names,\n",
    "        #        title=\"Risk classification Confusion Matrix\"\n",
    "        #    ), \n",
    "        #    \"roc_curve\": wandb.plot.roc_curve(\n",
    "        #        all_labels, \n",
    "        #        all_prob\n",
    "        #    ),\n",
    "        #    \"val_loss\": val_loss,\n",
    "        #    \"val_accuracy\": acc, \n",
    "        #    \"sensitivity\": sensitivity, \n",
    "        #    \"specificity\": specificity,\n",
    "        #    \"AUC\": auc, \"F1-score\": f1\n",
    "        #})\n",
    "            \n",
    "\n",
    "    return val_loss\n",
    "\n",
    "#model set to densenet121 with last layers to finetune\n",
    "def model():\n",
    "    dense = models.densenet121(weights = models.DenseNet121_Weights.DEFAULT)\n",
    "    dense.classifier = nn.Linear(dense.classifier.in_features, 2).to(device)\n",
    "    for name, param in dense.features.named_parameters():\n",
    "        if \"denseblock4\" not in name:\n",
    "            param.requires_grad = False         #requires_grad=False -> freeze the parameters\n",
    "    \n",
    "    for module in dense.features.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.eval()\n",
    "    dense.to(device)\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': dense.features.denseblock4.parameters(), 'lr': 1e-4},\n",
    "        {'params': dense.classifier.parameters(), 'lr': 1e-3}\n",
    "    ])\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    return dense, optimizer, criterion, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2a2eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, frames_path, not_all_frames=False, transform=None, target_transform=None):\n",
    "        self.img_paths = []\n",
    "        self.label_files = []\n",
    "        clinical_table = pd.read_parquet(annotations_file)\n",
    "        labels_table = clinical_table[[\"clinical_case\", \"risk_class\"]]\n",
    "        img_labels = dict(zip(labels_table['clinical_case'], labels_table['risk_class']))\n",
    "        self.labels_dict = {\n",
    "            \"benign\": 0, \n",
    "            \"malignant\": 1,\n",
    "            \"borderline\": 1     #merging malignant and borderline\n",
    "        }\n",
    "        self.risk_dict = {\n",
    "            0: \"benign\", \n",
    "            1: \"malignant\"\n",
    "        }\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.not_all_frames = not_all_frames\n",
    "\n",
    "        case_folders = [entry.name for entry in os.scandir(self.img_dir) if entry.is_dir()]\n",
    "\n",
    "        for i in range(len(case_folders)):\n",
    "            case_path = os.path.join(self.img_dir, case_folders[i])\n",
    "\n",
    "            for entry in os.scandir(case_path):\n",
    "                idx_des_frames = []\n",
    "                item_folder_path = os.path.join(case_path, entry.name)\n",
    "\n",
    "                for item_entry in sorted(os.scandir(item_folder_path), key=lambda e: e.name):\n",
    "\n",
    "                    if item_entry.is_file() and item_entry.name.startswith(entry.name) and (item_entry.name.endswith(('.jpeg', '.png'))):    #if entry is an image file\n",
    "                        self.img_paths.append(item_entry.path)\n",
    "                        self.label_files.append(self.labels_dict[img_labels[case_folders[i]]])\n",
    "\n",
    "                    #if item_entry.is_dir() and item_entry.name!='00000' and item_entry.name!='frames' and not_all_frames:\n",
    "                    #    idx_des_frames.append(int(item_entry.name))\n",
    "                    \n",
    "                    if item_entry.is_file() and item_entry.name.endswith('.mp4'):    #if entry is a video file\n",
    "                        #idx_des_frames=sorted(idx_des_frames)\n",
    "                        idx = extract_save_frames(item_entry.path, os.path.join(frames_path, entry.name))\n",
    "                        if not_all_frames==False:\n",
    "                            for s in range(idx):\n",
    "                                idx_des_frames.append(s)\n",
    "                        for s in range(idx):\n",
    "                            self.img_paths.append(os.path.join(frames_path, entry.name, f\"frame_{idx_des_frames[s]:04d}.jpeg\"))\n",
    "                            self.label_files.append(self.labels_dict[img_labels[case_folders[i]]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.label_files[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "038cb17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49aef3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_path = r\"/home/silvia.collicelli/data/controlled_dataset_metadata.parquet\"\n",
    "folder_path = r\"/home/silvia.collicelli/data/Dataset\"\n",
    "frames_path = r\"/home/silvia.collicelli/frames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = MyDataset(clinical_path, folder_path, frames_path, transform=None)  # raw, no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8f4ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Assign transforms AFTER split\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1b3b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs=1\n",
    "epochs=10\n",
    "class_names = [\"benign\", \"malignant\"]\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "#wandb.init(\n",
    "#    project=\"baseline_prova8\",\n",
    "#    config={\n",
    "#    \"learning_rate\": 0.0001,\n",
    "#    \"architecture\": \"DenseNet121\",\n",
    "#    \"dataset\": f\"ultrasound subset: {len(full_dataset)} images\",\n",
    "#    \"epochs\": epochs,\n",
    "#    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3eeed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [09:03<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.0419 | Val Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 286/1146 [02:16<06:50,  2.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m outputs = dense(images)\n\u001b[32m     22\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m optimizer.step()\n\u001b[32m     25\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/baseline_model/SynDiag_thesis/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/baseline_model/SynDiag_thesis/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/baseline_model/SynDiag_thesis/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for run in range(total_runs):\n",
    "    #wandb.init(name=f\"experiment_{run+1}\")\n",
    "    #wandb.config.update({\n",
    "    #\"seed\": 0,\n",
    "    #\"device\": str(device),\n",
    "    #\"augmentation\": \"flip+rotation+jitter\",\n",
    "    #\"optimizer\": \"Adam\",\n",
    "    #\"scheduler\": \"ReduceLROnPlateau\"\n",
    "    #})\n",
    "\n",
    "  \n",
    "    dense, optimizer, criterion, scheduler = model()\n",
    "  \n",
    "    for epoch in range(epochs):\n",
    "        dense.train()\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for images, labels in tqdm.tqdm(train_dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = dense(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss/len(train_dataloader)        \n",
    "        #wandb.log({\n",
    "        #    \"train_loss\": train_loss\n",
    "        #})\n",
    "        \n",
    "        # VALIDATION LOOP\n",
    "        val_loss = validate_model(dense, test_dataloader, criterion, device, log_images=False, batch_idx=1, class_names=class_names)\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:                       \n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    #wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
