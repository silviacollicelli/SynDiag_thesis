{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6de8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e7734a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set determinism\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b17cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#is this transform  okay?\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e59264e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the frames from a video and save them in a folder called frames\n",
    "def extract_save_frames(video_path, output_dir, idx_des_frames=[], not_all_frames=False):    \n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)       #elimina la cartella già presente se c'è\n",
    "    os.makedirs(output_dir, exist_ok=True) \n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    i, id, s = 0, 0 ,0\n",
    "\n",
    "    while True:\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        if not_all_frames:\n",
    "            if id < len(idx_des_frames) and i == idx_des_frames[id]:\n",
    "                frame_path = os.path.join(output_dir, f\"frame_{i:04d}.jpeg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                s += 1\n",
    "                id += 1\n",
    "        else:\n",
    "            frame_path = os.path.join(output_dir, f\"frame_{i:04d}.jpeg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            s += 1\n",
    "\n",
    "        i+=1  \n",
    "    return s\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=img_tensor.device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=img_tensor.device)\n",
    "    img_tensor = img_tensor * std[:, None, None] + mean[:, None, None]\n",
    "    return img_tensor.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09c3ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_image_table(images, predicted, labels, probs):\n",
    "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
    "    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(2)])\n",
    "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
    "        img = denormalize(img)\n",
    "        table.add_data(wandb.Image((img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)), pred, targ, *prob.numpy())\n",
    "    wandb.log({\"predictions_table\":table}, commit=False)\n",
    "\n",
    "#specificity = true negative rate\n",
    "#sensitivity = true positive rate\n",
    "#malignant 1 -> positive\n",
    "#benign 0 -> negative\n",
    "\n",
    "def validate_model(model, valid_dl, loss_func, device, log_images=False, batch_idx=0, class_names=None):\n",
    "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    model.eval()\n",
    "    correct, val_loss = 0, 0.0\n",
    "    all_preds, all_labels, all_prob, all_pos_prob = [], [], [], []\n",
    "    sensitivity, specificity, all_pos, all_neg = 0.0, 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            pos_prob = outputs.softmax(dim=1)[:,1]\n",
    "            val_loss += loss_func(outputs, labels)*labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_pos_prob.extend(pos_prob.cpu().numpy())\n",
    "            all_prob.extend(outputs.softmax(dim=1).cpu().numpy())\n",
    "\n",
    "            # Log one batch of images to the dashboard, always same batch_idx.\n",
    "            if i==batch_idx and log_images:\n",
    "                log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
    "        \n",
    "        all_labels = np.array(all_labels, dtype=int)\n",
    "        all_pos_prob = np.array(all_pos_prob, dtype=float)\n",
    "        all_prob = np.array(all_prob, dtype=float)\n",
    "\n",
    "        for i in range(len(all_labels)):\n",
    "            if all_labels[i] == 1: \n",
    "                all_pos += 1\n",
    "                if all_labels[i] == all_preds[i]:\n",
    "                    sensitivity += 1\n",
    "            elif all_labels[i] == 0:\n",
    "                all_neg += 1\n",
    "                if all_labels[i] == all_preds[i]:\n",
    "                    specificity += 1\n",
    "        \n",
    "        # Compute global metrics\n",
    "        sensitivity /= all_pos\n",
    "        specificity /= all_neg\n",
    "        val_loss /= len(valid_dl.dataset)\n",
    "        acc = correct / len(valid_dl.dataset)\n",
    "        auc = roc_auc_score(all_labels, all_pos_prob)\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "        wandb.log({\n",
    "            \"conf_mat\": wandb.plot.confusion_matrix(\n",
    "                preds=all_preds,\n",
    "                y_true=all_labels,\n",
    "                class_names=class_names,\n",
    "                title=\"Risk classification Confusion Matrix\"\n",
    "            ), \n",
    "            \"roc_curve\": wandb.plot.roc_curve(\n",
    "                all_labels, \n",
    "                all_prob\n",
    "            ),\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": acc, \n",
    "            \"sensitivity\": sensitivity, \n",
    "            \"specificity\": specificity,\n",
    "            \"AUC\": auc, \"F1-score\": f1\n",
    "        })\n",
    "            \n",
    "\n",
    "    return val_loss\n",
    "\n",
    "#model set to densenet121 with last layers to finetune\n",
    "def model():\n",
    "    dense = models.densenet121(weights = models.DenseNet121_Weights.DEFAULT)\n",
    "    dense.classifier = nn.Linear(dense.classifier.in_features, 2).to(device)\n",
    "    for name, param in dense.features.named_parameters():\n",
    "        if \"denseblock4\" not in name:\n",
    "            param.requires_grad = False         #requires_grad=False -> freeze the parameters\n",
    "    \n",
    "    for module in dense.features.modules():\n",
    "        if isinstance(module, nn.BatchNorm2d):\n",
    "            module.eval()\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': dense.features.denseblock4.parameters(), 'lr': 1e-4},\n",
    "        {'params': dense.classifier.parameters(), 'lr': 1e-3}\n",
    "    ])\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    return dense, optimizer, criterion, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a2eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, not_all_frames=True, transform=None, target_transform=None):\n",
    "        self.img_paths = []\n",
    "        self.label_files = []\n",
    "        clinical_table = pd.read_parquet(annotations_file)\n",
    "        labels_table = clinical_table[[\"clinical_case\", \"risk_class\"]]\n",
    "        img_labels = dict(zip(labels_table['clinical_case'], labels_table['risk_class']))\n",
    "        self.labels_dict = {\n",
    "            \"benign\": 0, \n",
    "            \"malignant\": 1,\n",
    "            \"borderline\": 1     #merging malignant and borderline\n",
    "        }\n",
    "        self.risk_dict = {\n",
    "            0: \"benign\", \n",
    "            1: \"malignant\"\n",
    "        }\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.not_all_frames = not_all_frames\n",
    "\n",
    "        case_folders = [entry.name for entry in os.scandir(self.img_dir) if entry.is_dir()]\n",
    "\n",
    "        for i in range(len(case_folders)):\n",
    "            case_path = os.path.join(self.img_dir, case_folders[i])\n",
    "\n",
    "            for entry in os.scandir(case_path):\n",
    "                idx_des_frames = []\n",
    "                item_folder_path = os.path.join(case_path, entry.name)\n",
    "\n",
    "                for item_entry in os.scandir(item_folder_path):\n",
    "\n",
    "                    if item_entry.is_file() and item_entry.name.startswith(entry.name) and (item_entry.name.endswith(('.jpeg', '.png'))):    #if entry is an image file\n",
    "                        self.img_paths.append(item_entry.path)\n",
    "                        self.label_files.append(self.labels_dict[img_labels[case_folders[i]]])\n",
    "\n",
    "                    if item_entry.is_dir() and item_entry.name!='00000' and item_entry.name!='frames' and not_all_frames:\n",
    "                        idx_des_frames.append(int(item_entry.name))\n",
    "                \n",
    "                    if item_entry.is_file() and item_entry.name.endswith('.mp4'):    #if entry is a video file\n",
    "                        idx = extract_save_frames(item_entry.path, os.path.join(entry.path, \"frames\"), idx_des_frames=idx_des_frames, not_all_frames=not_all_frames)\n",
    "                        if not_all_frames==False:\n",
    "                            for s in range(idx):\n",
    "                                idx_des_frames.append(s)\n",
    "                        for s in range(idx):\n",
    "                            self.img_paths.append(os.path.join(entry.path, \"frames\", f\"frame_{idx_des_frames[s]:04d}.jpeg\"))\n",
    "                            self.label_files.append(self.labels_dict[img_labels[case_folders[i]]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.label_files[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "038cb17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49aef3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_path = r\"C:\\Users\\utente\\Documents\\UNI\\MAGISTRALE\\tesi\\naive_baseline\\raw_dataset\\artifacts\\clinical_case_metadata.parquet\"\n",
    "folder_path = r\"C:\\Users\\utente\\Documents\\UNI\\MAGISTRALE\\tesi\\naive_baseline\\raw_dataset\\artifacts\\Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc11d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = MyDataset(clinical_path, folder_path, not_all_frames=True, transform=None)  # raw, no augmentation\n",
    "\n",
    "# Split\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Assign transforms AFTER split\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1b3b809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\utente\\Documents\\UNI\\MAGISTRALE\\tesi\\naive_baseline\\wandb\\run-20251029_162747-m5p4i72p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/collicellisilvia-personal/baseline_prova7/runs/m5p4i72p' target=\"_blank\">devout-resonance-2</a></strong> to <a href='https://wandb.ai/collicellisilvia-personal/baseline_prova7' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/collicellisilvia-personal/baseline_prova7' target=\"_blank\">https://wandb.ai/collicellisilvia-personal/baseline_prova7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/collicellisilvia-personal/baseline_prova7/runs/m5p4i72p' target=\"_blank\">https://wandb.ai/collicellisilvia-personal/baseline_prova7/runs/m5p4i72p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/collicellisilvia-personal/baseline_prova7/runs/m5p4i72p?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1d3a59b8350>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_runs=1\n",
    "epochs=15\n",
    "class_names = [\"benign\", \"malignant\"]\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "wandb.init(\n",
    "    project=\"baseline_prova7\",\n",
    "    config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"DenseNet121\",\n",
    "    \"dataset\": f\"ultrasound subset: {len(full_dataset)} images\",\n",
    "    \"epochs\": epochs,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3eeed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:14<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.5702 | Val Loss: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.2631 | Val Loss: 0.2455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:09<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.2466 | Val Loss: 0.2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:12<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.0792 | Val Loss: 0.4742\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:08<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.0804 | Val Loss: 0.3837\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:12<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.0752 | Val Loss: 0.2686\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:11<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.0500 | Val Loss: 0.3374\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:08<00:00,  1.26s/it]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.0782 | Val Loss: 0.3363\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>F1-score</td><td>▁██▂▃▄▃▃</td></tr><tr><td>sensitivity</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>specificity</td><td>▁██▃▄▅▄▄</td></tr><tr><td>train_loss</td><td>█▄▄▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁██▃▄▅▄▄</td></tr><tr><td>val_loss</td><td>█▁▁▅▄▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC</td><td>1</td></tr><tr><td>F1-score</td><td>0.71429</td></tr><tr><td>sensitivity</td><td>1</td></tr><tr><td>specificity</td><td>0.55556</td></tr><tr><td>train_loss</td><td>0.0782</td></tr><tr><td>val_accuracy</td><td>0.71429</td></tr><tr><td>val_loss</td><td>0.33632</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-resonance-2</strong> at: <a href='https://wandb.ai/collicellisilvia-personal/baseline_prova7/runs/m5p4i72p' target=\"_blank\">https://wandb.ai/collicellisilvia-personal/baseline_prova7/runs/m5p4i72p</a><br> View project at: <a href='https://wandb.ai/collicellisilvia-personal/baseline_prova7' target=\"_blank\">https://wandb.ai/collicellisilvia-personal/baseline_prova7</a><br>Synced 5 W&B file(s), 24 media file(s), 62 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251029_162747-m5p4i72p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for run in range(total_runs):\n",
    "    #wandb.init(name=f\"experiment_{run+1}\")\n",
    "    wandb.config.update({\n",
    "    \"seed\": 0,\n",
    "    \"device\": str(device),\n",
    "    \"augmentation\": \"flip+rotation+jitter\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"ReduceLROnPlateau\"\n",
    "    })\n",
    "\n",
    "  \n",
    "    dense, optimizer, criterion, scheduler = model()\n",
    "  \n",
    "    for epoch in range(epochs):\n",
    "        dense.train()\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for images, labels in tqdm.tqdm(train_dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = dense(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss/len(train_dataloader)        \n",
    "        wandb.log({\n",
    "            \"train_loss\": train_loss\n",
    "        })\n",
    "        \n",
    "        # VALIDATION LOOP\n",
    "        val_loss = validate_model(dense, test_dataloader, criterion, device, log_images=True, batch_idx=1, class_names=class_names)\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
